# ğŸ“Š Scenariusze Jutra - Dokumentacja Zbierania Danych

## Spis treÅ›ci
1. [PrzeglÄ…d projektu](#1-przeglÄ…d-projektu)
2. [Å¹rÃ³dÅ‚a danych](#2-ÅºrÃ³dÅ‚a-danych)
3. [Struktura listy ÅºrÃ³deÅ‚](#3-struktura-listy-ÅºrÃ³deÅ‚)
4. [Metodologia scrapowania](#4-metodologia-scrapowania)
5. [Format przechowywania danych](#5-format-przechowywania-danych)
6. [Instrukcje dla agentÃ³w AI](#6-instrukcje-dla-agentÃ³w-ai)
7. [Walidacja i czyszczenie danych](#7-walidacja-i-czyszczenie-danych)
8. [Harmonogram aktualizacji](#8-harmonogram-aktualizacji)

---

## 1. PrzeglÄ…d projektu

### Cel gÅ‚Ã³wny
Stworzenie narzÄ™dzia do analizy foresightowej generujÄ…cego scenariusze geopolityczne dla fikcyjnego paÅ„stwa **Atlantis** (czÅ‚onek UE i NATO) w perspektywie 12 i 36 miesiÄ™cy.

### Wymagania dotyczÄ…ce danych
- **Zakres czasowy**: Dane publikowane po **31 grudnia 2020 r.**
- **JÄ™zyki**: Angielski (priorytet), Polski
- **Wolumen bazowy**: Do 50 mln sÅ‚Ã³w
- **Wolumen docelowy (rozbudowa)**: Do 5 mld sÅ‚Ã³w

### Kategorie tematyczne danych
| Kategoria | Waga istotnoÅ›ci | Opis |
|-----------|-----------------|------|
| Technologie/PÃ³Å‚przewodniki | 30 | Produkcja GPU, Å‚aÅ„cuchy dostaw |
| Motoryzacja/EV | 15 | PrzemysÅ‚ europejski, konkurencja azjatycka |
| Ekonomia UE | 15 | PKB, trendy makroekonomiczne |
| Sytuacja Ukraina | 10 | Rozejm, inwestycje, infrastruktura |
| Inwestycje zagraniczne | 5 | USA/UE w Ukrainie, surowce krytyczne |
| Energia/OZE | 25 | Ceny ropy, transformacja energetyczna |

---

## 2. Å¹rÃ³dÅ‚a danych

### 2.1 Ministerstwa rzÄ…dowe (8 krajÃ³w Ã— 10 resortÃ³w)

#### Kraje objÄ™te analizÄ…
```
COUNTRIES = [
    "Germany",      # Niemcy
    "France",       # Francja  
    "United_Kingdom", # Wielka Brytania
    "United_States",  # USA
    "Russia",       # Rosja
    "China",        # Chiny
    "India",        # Indie
    "Saudi_Arabia"  # Arabia Saudyjska
]
```

#### Typy ministerstw
```
MINISTRY_TYPES = [
    "foreign_affairs",      # Sprawy zagraniczne
    "defense",              # Obrona
    "interior",             # Sprawy wewnÄ™trzne
    "economy",              # Gospodarka
    "trade",                # Handel
    "energy",               # Energia
    "climate",              # Klimat/Åšrodowisko
    "higher_education",     # Szkolnictwo wyÅ¼sze
    "digital_technology",   # Cyfryzacja/Nowe technologie
    "education"             # Edukacja
]
```

### 2.2 Instytucje miÄ™dzynarodowe i think-tanki

```
INSTITUTIONS = {
    # Instytucje miÄ™dzynarodowe
    "EU_Commission": {
        "name": "European Commission",
        "url": "https://ec.europa.eu",
        "type": "international_org",
        "priority": "high"
    },
    "NATO": {
        "name": "North Atlantic Treaty Organization",
        "url": "https://www.nato.int",
        "type": "international_org",
        "priority": "high"
    },
    "UN": {
        "name": "United Nations",
        "url": "https://www.un.org",
        "type": "international_org",
        "priority": "high"
    },
    "OECD": {
        "name": "Organisation for Economic Co-operation and Development",
        "url": "https://www.oecd.org",
        "type": "international_org",
        "priority": "high"
    },
    "GCC": {
        "name": "Gulf Cooperation Council",
        "url": "https://www.gcc-sg.org",
        "type": "international_org",
        "priority": "medium"
    },
    
    # Think-tanki
    "IISS": {
        "name": "International Institute for Strategic Studies",
        "url": "https://www.iiss.org",
        "type": "think_tank",
        "priority": "high"
    },
    "CSIS": {
        "name": "Center for Strategic and International Studies",
        "url": "https://www.csis.org",
        "type": "think_tank",
        "priority": "high"
    },
    "Chatham_House": {
        "name": "Chatham House",
        "url": "https://www.chathamhouse.org",
        "type": "think_tank",
        "priority": "high"
    },
    "ECFR": {
        "name": "European Council on Foreign Relations",
        "url": "https://ecfr.eu",
        "type": "think_tank",
        "priority": "high"
    },
    "Atlantic_Council": {
        "name": "Atlantic Council",
        "url": "https://www.atlanticcouncil.org",
        "type": "think_tank",
        "priority": "high"
    },
    "Kiel_Institute": {
        "name": "Kiel Institute for the World Economy",
        "url": "https://www.ifw-kiel.de",
        "type": "think_tank",
        "priority": "medium"
    },
    
    # GieÅ‚dy i instytucje finansowe
    "NASDAQ": {
        "name": "NASDAQ",
        "url": "https://www.nasdaq.com",
        "type": "financial",
        "priority": "medium"
    },
    "LSE_Group": {
        "name": "London Stock Exchange Group",
        "url": "https://www.lseg.com",
        "type": "financial",
        "priority": "medium"
    },
    "JPX": {
        "name": "Japan Exchange Group",
        "url": "https://www.jpx.co.jp/english",
        "type": "financial",
        "priority": "medium"
    }
}
```

---

## 3. Struktura listy ÅºrÃ³deÅ‚

### 3.1 Format pliku konfiguracyjnego ÅºrÃ³deÅ‚

KaÅ¼de ÅºrÃ³dÅ‚o powinno byÄ‡ opisane w formacie JSON z nastÄ™pujÄ…cÄ… strukturÄ…:

```json
{
  "source_id": "DE_MOD",
  "country": "Germany",
  "country_code": "DE",
  "ministry_type": "defense",
  "official_name": "Federal Ministry of Defence",
  "native_name": "Bundesministerium der Verteidigung",
  "base_url": "https://www.bmvg.de/en",
  "endpoints": {
    "news": "/news",
    "press_releases": "/press-releases",
    "publications": "/publications",
    "speeches": "/speeches"
  },
  "language": "en",
  "data_format": ["html", "pdf"],
  "scraping_method": "requests_bs4",
  "rate_limit_seconds": 2,
  "priority": "high",
  "tags": ["defense", "military", "nato", "security"],
  "date_filter": "2021-01-01",
  "active": true,
  "last_scraped": null,
  "notes": "English version available"
}
```

### 3.2 Hierarchia plikÃ³w ÅºrÃ³deÅ‚

```
data_sources/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ sources_master.json          # GÅ‚Ã³wna lista wszystkich ÅºrÃ³deÅ‚
â”‚   â”œâ”€â”€ countries.json                # Definicje krajÃ³w
â”‚   â”œâ”€â”€ ministry_types.json           # Typy ministerstw
â”‚   â””â”€â”€ institutions.json             # Instytucje miÄ™dzynarodowe
â”‚
â”œâ”€â”€ ministries/
â”‚   â”œâ”€â”€ germany/
â”‚   â”‚   â”œâ”€â”€ foreign_affairs.json
â”‚   â”‚   â”œâ”€â”€ defense.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ france/
â”‚   â”œâ”€â”€ united_kingdom/
â”‚   â”œâ”€â”€ united_states/
â”‚   â”œâ”€â”€ russia/
â”‚   â”œâ”€â”€ china/
â”‚   â”œâ”€â”€ india/
â”‚   â””â”€â”€ saudi_arabia/
â”‚
â”œâ”€â”€ institutions/
â”‚   â”œâ”€â”€ international_orgs/
â”‚   â”‚   â”œâ”€â”€ eu_commission.json
â”‚   â”‚   â”œâ”€â”€ nato.json
â”‚   â”‚   â”œâ”€â”€ un.json
â”‚   â”‚   â”œâ”€â”€ oecd.json
â”‚   â”‚   â””â”€â”€ gcc.json
â”‚   â”œâ”€â”€ think_tanks/
â”‚   â”‚   â”œâ”€â”€ iiss.json
â”‚   â”‚   â”œâ”€â”€ csis.json
â”‚   â”‚   â”œâ”€â”€ chatham_house.json
â”‚   â”‚   â”œâ”€â”€ ecfr.json
â”‚   â”‚   â”œâ”€â”€ atlantic_council.json
â”‚   â”‚   â””â”€â”€ kiel_institute.json
â”‚   â””â”€â”€ financial/
â”‚       â”œâ”€â”€ nasdaq.json
â”‚       â”œâ”€â”€ lse_group.json
â”‚       â””â”€â”€ jpx.json
â”‚
â””â”€â”€ urls/
    â”œâ”€â”€ verified_urls.csv             # Zweryfikowane URL-e
    â”œâ”€â”€ failed_urls.csv               # NiedziaÅ‚ajÄ…ce URL-e
    â””â”€â”€ sitemap_urls.csv              # URL-e z sitemapÃ³w
```

### 3.3 Format listy URL do scrapowania

Plik CSV z listÄ… wszystkich endpointÃ³w:

```csv
source_id,url,content_type,priority,last_check,status,retry_count
DE_MOD_NEWS,https://www.bmvg.de/en/news,news,high,2025-01-15,active,0
DE_MOD_PRESS,https://www.bmvg.de/en/press-releases,press,high,2025-01-15,active,0
FR_MAE_NEWS,https://www.diplomatie.gouv.fr/en/latest-news,news,high,2025-01-14,active,0
```

---

## 4. Metodologia scrapowania

### 4.1 Diagram przepÅ‚ywu danych

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lista ÅºrÃ³deÅ‚   â”‚â”€â”€â”€â”€â–¶â”‚  URL Discovery   â”‚â”€â”€â”€â”€â–¶â”‚  Content Fetch  â”‚
â”‚  (JSON/CSV)     â”‚     â”‚  (Sitemap/RSS)   â”‚     â”‚  (HTML/PDF)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Storage   â”‚â—€â”€â”€â”€â”€â”‚  NLP Processing  â”‚â—€â”€â”€â”€â”€â”‚  Text Extract   â”‚
â”‚  (PostgreSQL)   â”‚     â”‚  (spaCy/NLTK)    â”‚     â”‚  (BS4/PyPDF)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embeddings     â”‚â”€â”€â”€â”€â–¶â”‚  Vector Store    â”‚â”€â”€â”€â”€â–¶â”‚  LLM Analysis   â”‚
â”‚  (OpenAI/Local) â”‚     â”‚  (ChromaDB)      â”‚     â”‚  (Claude/GPT)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Metody pozyskiwania danych

| Metoda | Zastosowanie | Biblioteki Python |
|--------|--------------|-------------------|
| **Web Scraping** | Strony HTML | `requests`, `BeautifulSoup4`, `Scrapy` |
| **API REST** | Oficjalne API | `requests`, `aiohttp` |
| **RSS/Atom Feeds** | AktualnoÅ›ci | `feedparser` |
| **Sitemap Parsing** | Odkrywanie URL | `xml.etree`, `lxml` |
| **PDF Extraction** | Raporty, dokumenty | `PyPDF2`, `pdfplumber`, `pymupdf` |
| **Selenium** | Strony dynamiczne (JS) | `selenium`, `playwright` |

### 4.3 Strategia rate-limiting

```python
RATE_LIMITS = {
    "default": 2.0,           # 2 sekundy miÄ™dzy requestami
    "government": 3.0,        # Strony rzÄ…dowe - ostroÅ¼niej
    "think_tank": 1.5,        # Think-tanki
    "financial": 1.0,         # GieÅ‚dy
    "high_priority": 1.0,     # Pilne ÅºrÃ³dÅ‚a
    "respectful_max": 5.0     # Maksymalny limit dla wraÅ¼liwych stron
}
```

### 4.4 ObsÅ‚uga bÅ‚Ä™dÃ³w i retry

```python
RETRY_CONFIG = {
    "max_retries": 3,
    "backoff_factor": 2,      # WykÅ‚adniczy backoff
    "retry_on_status": [429, 500, 502, 503, 504],
    "timeout": 30,
    "connection_timeout": 10
}
```

---

## 5. Format przechowywania danych

### 5.1 Struktura bazy danych

```sql
-- Tabela ÅºrÃ³deÅ‚
CREATE TABLE sources (
    source_id VARCHAR(50) PRIMARY KEY,
    country VARCHAR(50),
    institution_type VARCHAR(50),
    name VARCHAR(200),
    base_url VARCHAR(500),
    language VARCHAR(10),
    priority VARCHAR(20),
    active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tabela dokumentÃ³w
CREATE TABLE documents (
    doc_id SERIAL PRIMARY KEY,
    source_id VARCHAR(50) REFERENCES sources(source_id),
    url VARCHAR(1000) UNIQUE,
    title VARCHAR(500),
    content TEXT,
    content_hash VARCHAR(64),
    publication_date DATE,
    scrape_date TIMESTAMP,
    word_count INTEGER,
    language VARCHAR(10),
    document_type VARCHAR(50),
    tags TEXT[],
    metadata JSONB
);

-- Tabela embeddings
CREATE TABLE embeddings (
    embedding_id SERIAL PRIMARY KEY,
    doc_id INTEGER REFERENCES documents(doc_id),
    chunk_index INTEGER,
    chunk_text TEXT,
    embedding VECTOR(1536),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indeksy dla wydajnoÅ›ci
CREATE INDEX idx_documents_source ON documents(source_id);
CREATE INDEX idx_documents_date ON documents(publication_date);
CREATE INDEX idx_documents_tags ON documents USING GIN(tags);
```

### 5.2 Struktura plikÃ³w lokalnych

```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ html/
â”‚   â”‚   â””â”€â”€ {source_id}/{YYYY-MM-DD}/{doc_hash}.html
â”‚   â””â”€â”€ pdf/
â”‚       â””â”€â”€ {source_id}/{YYYY-MM-DD}/{doc_hash}.pdf
â”‚
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ text/
â”‚   â”‚   â””â”€â”€ {source_id}/{doc_id}.txt
â”‚   â””â”€â”€ json/
â”‚       â””â”€â”€ {source_id}/{doc_id}.json
â”‚
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ {source_id}_embeddings.parquet
â”‚
â””â”€â”€ metadata/
    â”œâ”€â”€ scrape_logs/
    â””â”€â”€ statistics/
```

### 5.3 Format dokumentu przetworzonego (JSON)

```json
{
  "doc_id": "DE_MOD_20240115_a1b2c3",
  "source_id": "DE_MOD",
  "url": "https://www.bmvg.de/en/news/article-123",
  "title": "Germany increases defense spending",
  "content": "Full text content...",
  "summary": "AI-generated summary...",
  "publication_date": "2024-01-15",
  "scrape_date": "2025-01-20T14:30:00Z",
  "word_count": 1250,
  "language": "en",
  "document_type": "news_article",
  "entities": {
    "countries": ["Germany", "NATO"],
    "organizations": ["Bundeswehr", "European Union"],
    "persons": ["Boris Pistorius"],
    "topics": ["defense", "military spending"]
  },
  "tags": ["defense", "nato", "budget", "germany"],
  "sentiment": 0.15,
  "relevance_scores": {
    "atlantis_interest": 0.85,
    "topic_defense": 0.95,
    "topic_economy": 0.30
  },
  "metadata": {
    "author": "Press Office",
    "section": "News",
    "images": 2,
    "links_count": 5
  }
}
```

---

## 6. Instrukcje dla agentÃ³w AI

### 6.1 Zadanie 1: Generowanie listy URL ministerstw

**Prompt dla agenta:**
```
ZADANIE: Wygeneruj kompletnÄ… listÄ™ URL oficjalnych stron ministerstw dla projektu "Scenariusze jutra".

WYMAGANIA:
1. Dla kaÅ¼dego z 8 krajÃ³w (Niemcy, Francja, UK, USA, Rosja, Chiny, Indie, Arabia Saudyjska):
   - ZnajdÅº oficjalne strony 10 typÃ³w ministerstw
   - Priorytetowo traktuj wersje anglojÄ™zyczne
   - Zidentyfikuj sekcje: news, press releases, publications, speeches

2. Format wyjÅ›ciowy: JSON zgodny ze strukturÄ… z sekcji 3.1

3. Walidacja:
   - SprawdÅº czy URL odpowiada (status 200)
   - Zweryfikuj jÄ™zyk strony
   - PotwierdÅº datÄ™ ostatniej aktualizacji

4. Dla kaÅ¼dego ÅºrÃ³dÅ‚a okreÅ›l:
   - MetodÄ™ scrapowania (static/dynamic)
   - DostÄ™pnoÅ›Ä‡ RSS/API
   - StrukturÄ™ paginacji

OUTPUT: Plik ministries_urls_master.json
```

### 6.2 Zadanie 2: Tworzenie scraperÃ³w

**Prompt dla agenta:**
```
ZADANIE: StwÃ³rz moduÅ‚owy system scraperÃ³w w Pythonie.

WYMAGANIA TECHNICZNE:
1. Architektura:
   - Klasa bazowa `BaseScraper` z metodami: fetch, parse, store
   - Klasy pochodne dla rÃ³Å¼nych typÃ³w stron
   - ObsÅ‚uga async (aiohttp/asyncio)
   
2. FunkcjonalnoÅ›ci:
   - Rate limiting z konfiguracjÄ… per-source
   - Retry logic z exponential backoff
   - Proxy rotation (opcjonalnie)
   - User-agent rotation
   - Caching (Redis/SQLite)
   
3. Parsowanie:
   - Ekstrakcja tekstu z HTML (BeautifulSoup)
   - Ekstrakcja z PDF (pdfplumber)
   - Czyszczenie tekstu (usuwanie boilerplate)
   - Wykrywanie jÄ™zyka
   - Ekstrakcja metadanych (data, autor, tagi)

4. Storage:
   - Zapis do PostgreSQL
   - Eksport do Parquet/JSON
   - Deduplikacja (hash contentu)

5. Monitoring:
   - Logowanie (structlog)
   - Metryki (iloÅ›Ä‡ dokumentÃ³w, bÅ‚Ä™dy)
   - Alerty przy failure rate > 10%

STRUKTURA PLIKÃ“W:
scrapers/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py           # BaseScraper
â”œâ”€â”€ ministry.py       # MinistryScraper
â”œâ”€â”€ think_tank.py     # ThinkTankScraper
â”œâ”€â”€ financial.py      # FinancialScraper
â”œâ”€â”€ pdf_extractor.py  # PDFScraper
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ rate_limiter.py
â”‚   â”œâ”€â”€ text_cleaner.py
â”‚   â””â”€â”€ date_parser.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ scraper_config.yaml
â””â”€â”€ tests/
    â””â”€â”€ test_scrapers.py
```

### 6.3 Zadanie 3: Pipeline przetwarzania NLP

**Prompt dla agenta:**
```
ZADANIE: Zbuduj pipeline NLP do analizy dokumentÃ³w.

KOMPONENTY:
1. Text Preprocessing:
   - Tokenizacja (spaCy)
   - Lemmatyzacja
   - Usuwanie stopwords
   - Normalizacja

2. Named Entity Recognition:
   - Kraje i regiony
   - Organizacje
   - Osoby
   - Daty i wydarzenia

3. Topic Modeling:
   - Przypisanie do kategorii tematycznych (z sekcji 1)
   - Scoring relevance dla Atlantis

4. Sentiment Analysis:
   - OgÃ³lny sentiment
   - Sentiment per-entity
   - Tone detection (formal/informal)

5. Embedding Generation:
   - Chunking dokumentÃ³w (500 tokenÃ³w)
   - Generowanie embeddings (OpenAI/local model)
   - Storage w vector DB

6. Summarization:
   - Automatyczne streszczenia (max 200 sÅ‚Ã³w)
   - Ekstrakcja kluczowych informacji

OUTPUT: ModuÅ‚y Python + konfiguracja + testy
```

### 6.4 Zadanie 4: System wykrywania data poisoning

**Prompt dla agenta:**
```
ZADANIE: Zaimplementuj mechanizm wykrywania manipulacji danymi.

METODY DETEKCJI:
1. Anomaly Detection:
   - NagÅ‚e zmiany w frequency publikacji
   - Nietypowe wzorce jÄ™zykowe
   - Outliers w embedding space

2. Source Verification:
   - Cross-checking z wieloma ÅºrÃ³dÅ‚ami
   - Weryfikacja autorstwa
   - Sprawdzanie dat publikacji

3. Content Analysis:
   - Wykrywanie sprzecznoÅ›ci
   - Identyfikacja propagandy
   - Analiza bias

4. Technical Indicators:
   - Sprawdzanie domen
   - SSL certificates
   - WHOIS history

OUTPUT: ModuÅ‚ Python z API: verify_source(), detect_anomaly(), trust_score()
```

---

## 7. Walidacja i czyszczenie danych

### 7.1 ReguÅ‚y walidacji

```python
VALIDATION_RULES = {
    "url": {
        "required": True,
        "format": "valid_url",
        "max_length": 1000
    },
    "content": {
        "required": True,
        "min_words": 50,
        "max_words": 50000,
        "language": ["en", "pl"]
    },
    "publication_date": {
        "required": True,
        "min_date": "2021-01-01",
        "max_date": "today"
    },
    "source_id": {
        "required": True,
        "format": "valid_source_id"
    }
}
```

### 7.2 Pipeline czyszczenia tekstu

1. **Usuwanie HTML tags** - BeautifulSoup
2. **Normalizacja whitespace** - regex
3. **Usuwanie boilerplate** - readability-lxml
4. **Detekcja jÄ™zyka** - langdetect
5. **Usuwanie duplikatÃ³w** - simhash/minhash
6. **Spell checking** (opcjonalnie) - pyspellchecker

### 7.3 Quality metrics

| Metryka | PrÃ³g akceptacji | Opis |
|---------|-----------------|------|
| `content_length` | > 100 znakÃ³w | Minimalna dÅ‚ugoÅ›Ä‡ |
| `language_confidence` | > 0.8 | PewnoÅ›Ä‡ detekcji jÄ™zyka |
| `date_validity` | 100% | Poprawny format daty |
| `duplicate_rate` | < 5% | Procent duplikatÃ³w |
| `encoding_errors` | < 1% | BÅ‚Ä™dy kodowania |

---

## 8. Harmonogram aktualizacji

### 8.1 CzÄ™stotliwoÅ›Ä‡ scrapowania

| Typ ÅºrÃ³dÅ‚a | CzÄ™stotliwoÅ›Ä‡ | Uzasadnienie |
|------------|---------------|--------------|
| News feeds | Co 4 godziny | Szybko zmieniajÄ…ce siÄ™ |
| Press releases | Codziennie | Umiarkowana czÄ™stotliwoÅ›Ä‡ |
| Publications | Co tydzieÅ„ | Rzadko aktualizowane |
| Reports | Co miesiÄ…c | Kwartalne/roczne raporty |

### 8.2 Cron schedule

```bash
# News - co 4 godziny
0 */4 * * * /usr/bin/python3 /app/scrapers/run.py --type news

# Press releases - codziennie o 6:00
0 6 * * * /usr/bin/python3 /app/scrapers/run.py --type press

# Publications - niedziela o 3:00
0 3 * * 0 /usr/bin/python3 /app/scrapers/run.py --type publications

# Full rescan - pierwszy dzieÅ„ miesiÄ…ca
0 1 1 * * /usr/bin/python3 /app/scrapers/run.py --type full
```

---

## ZaÅ‚Ä…czniki

### A. PrzykÅ‚adowe URL-e ministerstw (do weryfikacji)

```yaml
Germany:
  foreign_affairs: https://www.auswaertiges-amt.de/en
  defense: https://www.bmvg.de/en
  economy: https://www.bmwk.de/en
  
France:
  foreign_affairs: https://www.diplomatie.gouv.fr/en
  defense: https://www.defense.gouv.fr/english
  economy: https://www.economie.gouv.fr/welcome-to-the-french-ministry-for-the-economy
  
United_Kingdom:
  foreign_affairs: https://www.gov.uk/government/organisations/foreign-commonwealth-development-office
  defense: https://www.gov.uk/government/organisations/ministry-of-defence
  economy: https://www.gov.uk/government/organisations/department-for-business-and-trade

United_States:
  foreign_affairs: https://www.state.gov
  defense: https://www.defense.gov
  economy: https://www.commerce.gov
  trade: https://ustr.gov
  energy: https://www.energy.gov
```

### B. Checklist przed uruchomieniem scrapera

- [ ] Zweryfikowano wszystkie URL-e (status 200)
- [ ] Skonfigurowano rate limiting
- [ ] Ustawiono prawidÅ‚owy User-Agent
- [ ] Sprawdzono robots.txt dla kaÅ¼dej domeny
- [ ] Przygotowano bazÄ™ danych
- [ ] Skonfigurowano logging
- [ ] Ustawiono alerty bÅ‚Ä™dÃ³w
- [ ] Przetestowano na maÅ‚ej prÃ³bce
- [ ] Zweryfikowano format output

### C. Kontakt i eskalacja

- **Problemy techniczne**: SprawdÅº logi w `/var/log/scrapers/`
- **Blokady IP**: UÅ¼yj proxy rotation lub zmniejsz rate
- **Zmiany struktury stron**: Zaktualizuj parsery w `/scrapers/parsers/`

---

*Dokument wersja 1.0 | Ostatnia aktualizacja: GrudzieÅ„ 2025*
